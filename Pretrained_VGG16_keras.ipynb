{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import random\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import os as os \n",
    "os.chdir('/home/himanshu/cats_dogs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 18s 0us/step\n",
      "58900480/58889256 [==============================] - 18s 0us/step\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Train on 2000 samples, validate on 800 samples\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.7226 - acc: 0.7500 - val_loss: 0.2912 - val_acc: 0.8812\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3584 - acc: 0.8585 - val_loss: 0.3276 - val_acc: 0.8688\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3268 - acc: 0.8745 - val_loss: 0.3306 - val_acc: 0.8588\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2542 - acc: 0.8960 - val_loss: 0.2542 - val_acc: 0.9038\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2104 - acc: 0.9225 - val_loss: 0.2768 - val_acc: 0.9062\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1995 - acc: 0.9240 - val_loss: 0.2839 - val_acc: 0.9038\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1818 - acc: 0.9310 - val_loss: 0.3627 - val_acc: 0.8700\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1657 - acc: 0.9330 - val_loss: 0.3383 - val_acc: 0.8988\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1274 - acc: 0.9520 - val_loss: 0.5196 - val_acc: 0.8675\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1254 - acc: 0.9540 - val_loss: 0.3817 - val_acc: 0.9012\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1151 - acc: 0.9560 - val_loss: 0.5689 - val_acc: 0.8700\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0892 - acc: 0.9670 - val_loss: 0.4032 - val_acc: 0.8975\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1032 - acc: 0.9605 - val_loss: 0.5028 - val_acc: 0.8812\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0750 - acc: 0.9720 - val_loss: 0.4655 - val_acc: 0.8988\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0644 - acc: 0.9775 - val_loss: 0.4598 - val_acc: 0.9062\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0629 - acc: 0.9790 - val_loss: 0.4625 - val_acc: 0.9025\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0584 - acc: 0.9810 - val_loss: 0.5678 - val_acc: 0.8775\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0611 - acc: 0.9770 - val_loss: 0.5650 - val_acc: 0.8975\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0506 - acc: 0.9810 - val_loss: 0.7124 - val_acc: 0.8712\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0368 - acc: 0.9880 - val_loss: 0.5951 - val_acc: 0.9050\n"
     ]
    }
   ],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = '/home/himanshu/cats_dogs/train'\n",
    "validation_data_dir = '/home/himanshu/cats_dogs/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,             ## Class labels not defined here, to be generated later\n",
    "        shuffle=False)              ## No random shuffling, so the data from one class gets stacked together\n",
    "    \n",
    "    ## Generating bottleneck features for training set\n",
    "    bottleneck_features_train = model.predict_generator(                    \n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_train.npy', 'w'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    ## Generating bottleneck features for validation set\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'w'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "    train_labels = np.array(\n",
    "        [0]*(nb_train_samples/2)+[1]*(nb_train_samples/2))     ## Generating labels for training classes\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "    validation_labels = np.array(\n",
    "        [0]*(nb_validation_samples/2)+[1]*(nb_validation_samples/2))   ## Generating labels for validation set classes\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path) ## Saving trained weights for the model added on top of VGG16 architecture \n",
    "\n",
    "## Calling the main initiation functions to save bottleneck features and use further to train the classifier(top_model)\n",
    "save_bottlebeck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
