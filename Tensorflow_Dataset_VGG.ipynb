{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change directory\n",
    "os.chdir(\"/home/saurabh/Downloads/CatDog\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/saurabh/Downloads/CatDog'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get working directory\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a list containing filenames \n",
    "image_paths = []\n",
    "\n",
    "for names in os.listdir(\"/home/saurabh/Downloads/CatDog\"):\n",
    "    image_paths.append(names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_paths'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retreiving filenames \n",
    "#Commented as it has long ouput \n",
    "'''image_paths''' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No. of images \n",
    "len(image_paths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating tensor object for images \n",
    "data_images = tf.constant(image_paths)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain the labels corresponding to each image \n",
    "labels = []\n",
    "\n",
    "for names in os.listdir(\"/home/saurabh/Downloads/CatDog\"):\n",
    "    \n",
    "    if names.startswith(\"c\"):\n",
    "        label = 0\n",
    "    elif names.startswith(\"d\"):\n",
    "        label = 1\n",
    "    labels.append(label)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating tensor object for labels\n",
    "data_labels = tf.constant(labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train and validation dataset from tensor objects\n",
    "tr_data = tf.data.Dataset.from_tensor_slices((data_images[:20000], data_labels[:20000]))  \n",
    "val_data = tf.data.Dataset.from_tensor_slices((data_images[20000:], data_labels[20000:])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a generic iterator object \n",
    "iterator = tf.data.Iterator.from_structure(tr_data.output_types,tr_data.output_shapes) \n",
    " \n",
    "#Accessing the next element from the iterator \n",
    "next_element = iterator.get_next()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing iterator for train and validation set\n",
    "train_init_op = iterator.make_initializer(tr_data) \n",
    "val_init_op = iterator.make_initializer(val_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with tf.Session() as sess:\\n    sess.run(train_init_op)\\n    while True:\\n        try:\\n            elem = sess.run(next_element)\\n            print(elem)\\n             \\n        except tf.errors.OutOfRangeError: \\n            print(\"End of training dataset.\")\\n            break '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retreiving created data with images and label\n",
    "#Commented as it has long ouput \n",
    "\n",
    "'''with tf.Session() as sess:\n",
    "    sess.run(train_init_op)\n",
    "    while True:\n",
    "        try:\n",
    "            elem = sess.run(next_element)\n",
    "            print(elem)\n",
    "             \n",
    "        except tf.errors.OutOfRangeError: \n",
    "            print(\"End of training dataset.\")\n",
    "            break '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining an input parser\n",
    "def parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "    \n",
    "\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "      \n",
    "    # Converting to float values \n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize_images(image, [64, 64]) \n",
    "    return image, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = tr_data.map(parse_function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data.map(parse_function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining augmentation functions \n",
    "def img_augmentation(image, label):\n",
    "    \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_contrast(image, 0.2, 1.8, seed=1) \n",
    "    image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)\n",
    "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "    image = tf.image.random_hue(image, max_delta=32.0 / 255) \n",
    "   \n",
    "    # Make sure the image is still in [0, 1]\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "    return image, label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentated Data \n",
    "Aug_data = tr_data.map(img_augmentation, num_parallel_calls=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating augmentated data with the trainset \n",
    "train_data = tr_data.concatenate(Aug_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the trainset\n",
    "train_data = train_data.shuffle(len(image_paths)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch size \n",
    "train_data = train_data.batch(16) \n",
    "train_data = train_data.prefetch(1)  \n",
    "val_data = val_data.batch(16) \n",
    "val_data = val_data.prefetch(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = train_data.make_initializable_iterator() \n",
    " \n",
    "#Accessing the next element from the iterator \n",
    "images, labels = iterator.get_next()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext_1:0' shape=(?, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Image shape\n",
    "images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext_1:1' shape=(?,) dtype=int32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labels shape \n",
    "labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and validation set iterator initialization \n",
    "training_init_op = iterator.make_initializer(train_data)   \n",
    "valid_init_op = iterator.make_initializer(val_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with tf.Session() as sess:\\n    sess.run(training_init_op) \\n    for i in range(5):\\n        elem = sess.run(images) \\n        print(elem)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retreiving image arrays after parsing \n",
    "#Commented as it has long ouput \n",
    "\n",
    "'''with tf.Session() as sess:\n",
    "    sess.run(training_init_op) \n",
    "    for i in range(5):\n",
    "        elem = sess.run(images) \n",
    "        print(elem)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking layers as per VGG first block \n",
    "conv1 = tf.layers.conv2d(images, filters= 64, kernel_size= (3,3), strides=(1,1), activation=tf.nn.relu, kernel_initializer= tf.truncated_normal_initializer)  \n",
    "conv2 = tf.layers.conv2d(conv1, filters= 64, kernel_size= (3,3), strides=(1,1), activation=tf.nn.relu)   \n",
    "max1 = tf.layers.max_pooling2d(conv2, pool_size=(2,2), strides = (2,2)) \n",
    "flatten = tf.layers.flatten(max1) \n",
    "\n",
    "#Adding fully connected layers \n",
    "fc1 = tf.layers.dense(flatten, 512, activation= tf.nn.sigmoid, kernel_initializer=tf.truncated_normal_initializer) \n",
    "fc2 = tf.layers.dense(fc1, 2)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(labels= labels, logits=fc2)) \n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "# get accuracy\n",
    "prediction = tf.argmax(fc2, 1, output_type=tf.int32)\n",
    "equality = tf.equal(prediction, labels) \n",
    "accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))    \n",
    "init_op = tf.global_variables_initializer()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 12.746, training accuracy: 31.25%\n",
      "Epoch: 5, loss: 11.683, training accuracy: 56.25%\n",
      "Epoch: 10, loss: 13.973, training accuracy: 37.50%\n",
      "Epoch: 15, loss: 10.829, training accuracy: 68.75%\n",
      "Epoch: 20, loss: 10.679, training accuracy: 68.75%\n",
      "Epoch: 25, loss: 10.833, training accuracy: 50.00%\n",
      "Epoch: 30, loss: 11.874, training accuracy: 56.25%\n",
      "Epoch: 35, loss: 11.877, training accuracy: 43.75%\n",
      "Epoch: 40, loss: 12.370, training accuracy: 43.75%\n",
      "Epoch: 45, loss: 12.052, training accuracy: 37.50%\n",
      "Epoch: 50, loss: 16.115, training accuracy: 25.00%\n",
      "Epoch: 55, loss: 11.513, training accuracy: 43.75%\n",
      "Epoch: 60, loss: 12.758, training accuracy: 18.75%\n",
      "Epoch: 65, loss: 11.700, training accuracy: 43.75%\n",
      "Epoch: 70, loss: 11.385, training accuracy: 37.50%\n",
      "Epoch: 75, loss: 10.437, training accuracy: 62.50%\n",
      "Epoch: 80, loss: 9.796, training accuracy: 75.00%\n",
      "Epoch: 85, loss: 12.275, training accuracy: 43.75%\n",
      "Epoch: 90, loss: 10.933, training accuracy: 56.25%\n",
      "Epoch: 95, loss: 10.580, training accuracy: 75.00%\n",
      "Average validation set accuracy over 200 iterations is 54.66%\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    sess.run(training_init_op)\n",
    "    for i in range(epochs):\n",
    "         \n",
    "        l, _, acc = sess.run([loss, optimizer, accuracy])\n",
    "        if i % 5== 0:\n",
    "            print(\"Epoch: {}, loss: {:.3f}, training accuracy: {:.2f}%\".format(i, l, acc * 100)) \n",
    "            \n",
    "    valid_iters= 200\n",
    "    sess.run(valid_init_op)\n",
    "    avg_acc = 0\n",
    "    for i in range(valid_iters):\n",
    "        acc = sess.run([accuracy]) \n",
    "        avg_acc += acc[0] \n",
    "    print(\"Average validation set accuracy over {} iterations is {:.2f}%\".format(valid_iters, (avg_acc / valid_iters) * 100))\n",
    "\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
