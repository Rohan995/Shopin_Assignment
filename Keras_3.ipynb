{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishant/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishant/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:78: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/nishant/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=125, epochs=50, validation_steps=800)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 1927s 15s/step - loss: 0.5579 - acc: 0.7265 - val_loss: 0.4917 - val_acc: 0.8025\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1503s 12s/step - loss: 0.4437 - acc: 0.7880 - val_loss: 0.3801 - val_acc: 0.8725\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 1501s 12s/step - loss: 0.2616 - acc: 0.9005 - val_loss: 0.3444 - val_acc: 0.8900\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 1501s 12s/step - loss: 0.2208 - acc: 0.9185 - val_loss: 0.3138 - val_acc: 0.8975\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1502s 12s/step - loss: 0.1747 - acc: 0.9335 - val_loss: 0.3515 - val_acc: 0.8888\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 1500s 12s/step - loss: 0.1488 - acc: 0.9425 - val_loss: 0.3460 - val_acc: 0.9012\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 1499s 12s/step - loss: 0.1121 - acc: 0.9545 - val_loss: 0.3678 - val_acc: 0.8988\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 1499s 12s/step - loss: 0.0982 - acc: 0.9645 - val_loss: 0.4198 - val_acc: 0.8962\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 1500s 12s/step - loss: 0.1328 - acc: 0.9530 - val_loss: 0.3212 - val_acc: 0.8975\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 1502s 12s/step - loss: 0.0847 - acc: 0.9675 - val_loss: 0.4969 - val_acc: 0.9113\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 1501s 12s/step - loss: 0.0585 - acc: 0.9770 - val_loss: 0.3941 - val_acc: 0.9100\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 1499s 12s/step - loss: 0.0677 - acc: 0.9765 - val_loss: 0.3262 - val_acc: 0.9062\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 1499s 12s/step - loss: 0.0628 - acc: 0.9795 - val_loss: 0.3668 - val_acc: 0.9125\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 1500s 12s/step - loss: 0.0568 - acc: 0.9805 - val_loss: 0.4298 - val_acc: 0.9075\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 1500s 12s/step - loss: 0.0375 - acc: 0.9860 - val_loss: 0.5063 - val_acc: 0.9100\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 1502s 12s/step - loss: 0.0630 - acc: 0.9755 - val_loss: 0.3857 - val_acc: 0.9175\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 1501s 12s/step - loss: 0.0390 - acc: 0.9855 - val_loss: 0.5001 - val_acc: 0.9050\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 1501s 12s/step - loss: 0.0393 - acc: 0.9860 - val_loss: 0.5823 - val_acc: 0.9100\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 1500s 12s/step - loss: 0.0461 - acc: 0.9900 - val_loss: 0.5077 - val_acc: 0.9125\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 1500s 12s/step - loss: 0.0334 - acc: 0.9905 - val_loss: 0.4204 - val_acc: 0.9038\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 1498s 12s/step - loss: 0.0367 - acc: 0.9930 - val_loss: 0.4878 - val_acc: 0.9062\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 1498s 12s/step - loss: 0.0348 - acc: 0.9865 - val_loss: 0.5680 - val_acc: 0.9012\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 1497s 12s/step - loss: 0.0212 - acc: 0.9945 - val_loss: 0.5296 - val_acc: 0.9137\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 1501s 12s/step - loss: 0.0170 - acc: 0.9935 - val_loss: 0.5863 - val_acc: 0.9075\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 1511s 12s/step - loss: 0.0221 - acc: 0.9935 - val_loss: 0.4984 - val_acc: 0.9137\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 1503s 12s/step - loss: 0.0231 - acc: 0.9930 - val_loss: 0.5065 - val_acc: 0.9113\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 1497s 12s/step - loss: 0.0118 - acc: 0.9955 - val_loss: 0.6533 - val_acc: 0.8975\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 1498s 12s/step - loss: 0.0345 - acc: 0.9890 - val_loss: 0.5892 - val_acc: 0.9187\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 1496s 12s/step - loss: 0.0368 - acc: 0.9890 - val_loss: 0.4294 - val_acc: 0.9187\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 1496s 12s/step - loss: 0.0196 - acc: 0.9955 - val_loss: 0.5144 - val_acc: 0.9200\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 1498s 12s/step - loss: 0.0193 - acc: 0.9950 - val_loss: 0.5253 - val_acc: 0.9175\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 1502s 12s/step - loss: 0.0142 - acc: 0.9945 - val_loss: 0.5110 - val_acc: 0.9125\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 1502s 12s/step - loss: 0.0218 - acc: 0.9925 - val_loss: 0.5361 - val_acc: 0.9163\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 1500s 12s/step - loss: 0.0247 - acc: 0.9935 - val_loss: 0.6175 - val_acc: 0.8762\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 1498s 12s/step - loss: 0.0229 - acc: 0.9930 - val_loss: 0.5880 - val_acc: 0.9025\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 1497s 12s/step - loss: 0.0136 - acc: 0.9955 - val_loss: 0.4595 - val_acc: 0.9100\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 1496s 12s/step - loss: 0.0128 - acc: 0.9965 - val_loss: 0.6131 - val_acc: 0.9087\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 1496s 12s/step - loss: 0.0068 - acc: 0.9975 - val_loss: 0.6523 - val_acc: 0.9125\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 1495s 12s/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.5819 - val_acc: 0.9175\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 1496s 12s/step - loss: 0.0038 - acc: 0.9985 - val_loss: 0.6128 - val_acc: 0.9250\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 1585s 13s/step - loss: 0.0070 - acc: 0.9965 - val_loss: 0.5346 - val_acc: 0.9213\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 1639s 13s/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.5273 - val_acc: 0.9137\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 1705s 14s/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.6460 - val_acc: 0.9075\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 1592s 13s/step - loss: 0.0065 - acc: 0.9975 - val_loss: 0.6068 - val_acc: 0.9163\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 1531s 12s/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.5941 - val_acc: 0.9125\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 1549s 12s/step - loss: 0.0093 - acc: 0.9965 - val_loss: 0.6498 - val_acc: 0.9187\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 1684s 13s/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.6807 - val_acc: 0.9175\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 1583s 13s/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.6362 - val_acc: 0.9163\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 1789s 14s/step - loss: 0.0069 - acc: 0.9975 - val_loss: 0.6616 - val_acc: 0.9187\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 1577s 13s/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6407 - val_acc: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b64f00d50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "# build the VGG16 network\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape = (150,150,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model =  Model(input = model.input, output = top_model(model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
