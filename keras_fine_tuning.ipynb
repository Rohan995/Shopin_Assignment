{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:39: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:79: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/shubham/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:79: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=125, epochs=50, validation_steps=800)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 1519s 12s/step - loss: 0.4911 - acc: 0.9250 - val_loss: 0.8586 - val_acc: 0.8875\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1508s 12s/step - loss: 0.5410 - acc: 0.9285 - val_loss: 0.8586 - val_acc: 0.8875\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 1505s 12s/step - loss: 0.4480 - acc: 0.9275 - val_loss: 0.8586 - val_acc: 0.8875\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 1575s 13s/step - loss: 0.5123 - acc: 0.9210 - val_loss: 0.8586 - val_acc: 0.8875\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1474s 12s/step - loss: 0.5594 - acc: 0.9235 - val_loss: 0.8586 - val_acc: 0.8875\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 1470s 12s/step - loss: 0.5724 - acc: 0.9150 - val_loss: 0.8586 - val_acc: 0.8875\n",
      "Epoch 7/50\n",
      "124/125 [============================>.] - ETA: 1s - loss: 0.5003 - acc: 0.9254"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "#path to the training data git init [project-name]\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "# building the VGG16 network\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "#model.add(top_model)\n",
    "model = Model(input=model.input,output=top_model(model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# preparing data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Generating the training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Generating the validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
