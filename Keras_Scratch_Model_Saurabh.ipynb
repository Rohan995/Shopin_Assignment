{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import libraries \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense \n",
    "from keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/saurabh'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check working directory \n",
    "import os\n",
    "os.getcwd()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define img dimension\n",
    "img_width, img_height = 150,150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directories \n",
    "train_data_dir = 'Downloads/Data/train'\n",
    "validation_data_dir = 'Downloads/Data/validation' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = 2000\n",
    "num_validation_samples = 800\n",
    "epochs = 20\n",
    "batch_size = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channel_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layers to the model \n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, (3,3), input_shape= input_shape)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3))) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(1)) \n",
    "model.add(Activation('sigmoid')) \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "125/125 [==============================] - 48s 386ms/step - loss: 0.8393 - acc: 0.5300 - val_loss: 0.6725 - val_acc: 0.6088\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 45s 363ms/step - loss: 0.6711 - acc: 0.6090 - val_loss: 0.6230 - val_acc: 0.6687\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 47s 378ms/step - loss: 0.6474 - acc: 0.6520 - val_loss: 0.6228 - val_acc: 0.6575\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 43s 340ms/step - loss: 0.6305 - acc: 0.6700 - val_loss: 0.6184 - val_acc: 0.6475\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 44s 350ms/step - loss: 0.6195 - acc: 0.6945 - val_loss: 0.6099 - val_acc: 0.6913\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 45s 360ms/step - loss: 0.6020 - acc: 0.6910 - val_loss: 0.5984 - val_acc: 0.6887\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 47s 379ms/step - loss: 0.5908 - acc: 0.7040 - val_loss: 0.5783 - val_acc: 0.6937\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 46s 371ms/step - loss: 0.5693 - acc: 0.7170 - val_loss: 0.6932 - val_acc: 0.7000\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 81s 647ms/step - loss: 0.5718 - acc: 0.7300 - val_loss: 0.5627 - val_acc: 0.7238\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 81s 650ms/step - loss: 0.5455 - acc: 0.7320 - val_loss: 0.5678 - val_acc: 0.7225\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 80s 641ms/step - loss: 0.5627 - acc: 0.7320 - val_loss: 0.5628 - val_acc: 0.7300\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 77s 617ms/step - loss: 0.5468 - acc: 0.7420 - val_loss: 0.5622 - val_acc: 0.7212\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 82s 654ms/step - loss: 0.5436 - acc: 0.7435 - val_loss: 0.5670 - val_acc: 0.7400\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 46s 368ms/step - loss: 0.5345 - acc: 0.7430 - val_loss: 0.5462 - val_acc: 0.7262\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 43s 347ms/step - loss: 0.5154 - acc: 0.7595 - val_loss: 0.5443 - val_acc: 0.7350\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 45s 360ms/step - loss: 0.5304 - acc: 0.7505 - val_loss: 0.5409 - val_acc: 0.7462\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 45s 359ms/step - loss: 0.5235 - acc: 0.7640 - val_loss: 0.5398 - val_acc: 0.7550\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 46s 369ms/step - loss: 0.4978 - acc: 0.7755 - val_loss: 0.5561 - val_acc: 0.7388\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 48s 383ms/step - loss: 0.5009 - acc: 0.7740 - val_loss: 0.5426 - val_acc: 0.7288\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 46s 366ms/step - loss: 0.4904 - acc: 0.7750 - val_loss: 0.5513 - val_acc: 0.7338\n"
     ]
    }
   ],
   "source": [
    "# Augmentation configuration for training \n",
    "train_datagen = ImageDataGenerator(rescale = 1. / 255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True) \n",
    "\n",
    "# Testset rescaling \n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator( \n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size)\n",
    "\n",
    "# Saving weights \n",
    "model.save_weights('first_try.h5') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
